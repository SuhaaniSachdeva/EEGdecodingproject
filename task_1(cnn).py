# -*- coding: utf-8 -*-
"""Task 1(CNN).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I78kg06eJhoLWDdrsLoNA4R0TRPluraA
"""

!pip install mne -q
!pip install braindecode eegdash -q

import os, zipfile
import numpy as np
import mne
mne.set_log_level("ERROR")

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from braindecode.datasets import BaseConcatDataset
from braindecode.preprocessing import preprocess, Preprocessor, create_windows_from_events
from braindecode.models import EEGNeX
from sklearn.model_selection import train_test_split
from sklearn.utils import check_random_state
from typing import Optional
from torch.nn import Module
from torch.optim.lr_scheduler import LRScheduler
from tqdm import tqdm
import copy
from joblib import Parallel, delayed

try:
    from eegdash.dataset import EEGChallengeDataset
    from eegdash.hbn.windows import (
        annotate_trials_with_target,
        add_aux_anchors,
        add_extras_columns,
        keep_only_recordings_with,

    )

    def safe_drop_if_missing_events(recording, required_events):
        return recording

except ImportError:
    print("Warning: eegdash not installed. Cannot run data loading sections.")
#ENCODER
class EEGEncoder(nn.Module):
    def __init__(self, chans=129, samples=200):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 16, (chans, 5), padding=(0, 2)),
            nn.BatchNorm2d(16),
            nn.ELU(),

            nn.Conv2d(16, 32, (1, 5), padding=(0, 2)),
            nn.BatchNorm2d(32),
            nn.ELU(),

            nn.AvgPool2d((1, 2)),
        )
        self.out_dim = 32 * (samples // 2)

    def forward(self, x):
        x = x.unsqueeze(1)
        z = self.conv(x).flatten(1)
        return z

class ColumnDecoder(nn.Module):
    def __init__(self, in_dim, chans=129):
        super().__init__()
        self.fc = nn.Sequential(
            nn.Linear(in_dim, 256),
            nn.ELU(),
            nn.Linear(256, chans),
        )

    def forward(self, z):
        return self.fc(z)

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

#data
zip_path = "/content/R11_mini_L100_bdf.zip"
extract_root = "/content/R11_mini_L100_bdf"

if not os.path.exists(extract_root):
    if os.path.exists(zip_path):
        with zipfile.ZipFile(zip_path, "r") as z:
            z.extractall("/content")
    else:
        print(f"Warning: Zip file not found at {zip_path}. Cannot load data.")

BIDS_ROOT = None
for root, dirs, files in os.walk("/content"):
    if "dataset_description.json" in files and root.endswith("R11_mini_L100_bdf"):
        BIDS_ROOT = root
        break

PRETRAINED_WEIGHTS_PATH = "encoder_passive_maskedSSL.pt"
if BIDS_ROOT is None:
    print("FATAL ERROR: BIDS_ROOT not found. Pretraining/Fine-tuning cannot proceed without data.")

print("Step 1: pretrainig")


def collect_passive_bdfs(root):
    """Collects BDF files only for passive tasks."""
    PASSIVE_LABELS = [
        "RestingState", "surroundSupp",
        "DespicableMe", "DiaryOfAWimpyKid", "FunwithFractals", "ThePresent"
    ]
    bdfs = []
    if root is None: return bdfs

    for sub in os.listdir(root):
        if not sub.startswith("sub-"):
            continue
        eeg_dir = os.path.join(root, sub, "eeg")
        if not os.path.isdir(eeg_dir):
            continue
        for f in os.listdir(eeg_dir):
            if f.endswith(".bdf"):
                if any(f"_task-{label}_" in f for label in PASSIVE_LABELS):
                    bdfs.append(os.path.join(eeg_dir, f))
    return sorted(bdfs)

PASSIVE_BDFS = collect_passive_bdfs(BIDS_ROOT)
print("\n--- PRETRAINING DATA ---")
print("Total PASSIVE BDF files found:", len(PASSIVE_BDFS))



class PassiveWindowsDataset(Dataset):
    """Precomputes window indices and lazily loads EEG segments."""
    def __init__(self, bdf_list, win_sec=2.0, sfreq=100.0):
        self.paths = bdf_list
        self.sfreq = sfreq
        self.win_samples = int(win_sec * sfreq)
        self.cache = {}
        self.index = []

        print("\nScanning files to build window index...")
        for i, path in enumerate(self.paths):
            raw = mne.io.read_raw_bdf(path, preload=False, verbose="ERROR")
            total_samples = raw.n_times
            if total_samples < self.win_samples:
                continue

            for start in range(0, total_samples - self.win_samples, self.win_samples):
                self.index.append((i, start))

        print(f"Total windows indexed: {len(self.index)}")

    def __len__(self):
        return len(self.index)

    def _load_data_for(self, file_idx):
        path = self.paths[file_idx]
        if path not in self.cache:
            raw = mne.io.read_raw_bdf(path, preload=True, verbose="ERROR")
            data = raw.get_data()
            self.cache[path] = data
        return self.cache[path]

    def __getitem__(self, idx):
        file_idx, start = self.index[idx]
        data = self._load_data_for(file_idx)
        seg = data[:, start:start + self.win_samples]
        return torch.tensor(seg, dtype=torch.float32)

dataset_ssl = PassiveWindowsDataset(PASSIVE_BDFS, win_sec=2.0, sfreq=100.0)
loader_ssl = DataLoader(dataset_ssl, batch_size=400, shuffle=True)
encoder = EEGEncoder().to(device)
decoder = ColumnDecoder(encoder.out_dim).to(device)

print("Encoder latent dim:", encoder.out_dim)


# masked self supervised learning
if BIDS_ROOT is not None and len(PASSIVE_BDFS) > 0:
    print("\n--- STARTING PRETRAINING (10 Epochs) ---")
    EPOCHS = 10
    LR = 1e-3

    optimizer = torch.optim.Adam(
        list(encoder.parameters()) + list(decoder.parameters()),
        lr=LR,
    )
    loss_fn = nn.MSELoss()

    for epoch in range(EPOCHS):
        encoder.train()
        decoder.train()
        epoch_loss = 0.0
        steps = 0

        for batch_idx, X in enumerate(tqdm(loader_ssl, desc=f"Epoch {epoch+1}/{EPOCHS}")):
            X = X.to(device)
            B, C, T = X.shape

            col_idx = torch.randint(0, T, (B,), device=device)
            masked = X.clone()

            for b in range(B):
                masked[b, :, col_idx[b]] = 0.0

            z = encoder(masked)
            pred = decoder(z)

            target_cols = torch.stack(
                [X[b, :, col_idx[b]] for b in range(B)],
                dim=0
            )

            loss = loss_fn(pred, target_cols)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()
            steps += 1

        avg_epoch_loss = epoch_loss / steps
        print(f"\n➡️ Epoch {epoch+1} average SSL loss: {avg_epoch_loss:.6f}")

 # save encoder
    torch.save(encoder.state_dict(), PRETRAINED_WEIGHTS_PATH)
    print(f"\nSaved pretrained encoder to {PRETRAINED_WEIGHTS_PATH}")
else:
    print("\nSkipping pretraining due to missing data.")

print("part 2 finetuning")
DATA_DIR = Path("data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

ACTIVE_TASKS = [
    "contrastChangeDetection",
]

all_active_datasets = []
print(f"Loading data for active tasks: {', '.join(ACTIVE_TASKS)}")

for task_name in ACTIVE_TASKS:
    try:
        ds = EEGChallengeDataset(
            task=task_name,
            release="R5",
            cache_dir=DATA_DIR,
            mini=True
        )
        all_active_datasets.append(ds)
        print(f"Successfully loaded {task_name} with {len(ds.datasets)} recordings.")
    except Exception as e:
        print(f"Warning: Could not load {task_name}. Skipping. Error: {e}")

dataset_ccd = BaseConcatDataset(all_active_datasets)
print(f"Total number of active recordings across all tasks: {len(dataset_ccd.datasets)}")


# windows of interest
EPOCH_LEN_S = 2.0
SFREQ = 100

REQUIRED_EVENTS = ["stimulus_onset", "response_onset"]
dataset_ccd.datasets = [d for d in dataset_ccd.datasets if d is not None]

assert len(dataset_ccd.datasets) > 0, "FATAL: CCD dataset is empty after filtering. Check data or environment setup."


transformation_offline = [
    Preprocessor(
        annotate_trials_with_target,
        target_field="rt_from_stimulus", epoch_length=EPOCH_LEN_S,
        require_stimulus=True, require_response=True,
        apply_on_array=False,
    ),
    Preprocessor(add_aux_anchors, apply_on_array=False),
]
preprocess(dataset_ccd, transformation_offline, n_jobs=1)

ANCHOR = "stimulus_anchor"
SHIFT_AFTER_STIM = 0.5
WINDOW_LEN = 2.0

dataset = keep_only_recordings_with(ANCHOR, dataset_ccd)

single_windows = create_windows_from_events(
    dataset,
    mapping={ANCHOR: 0},
    trial_start_offset_samples=int(SHIFT_AFTER_STIM * SFREQ),
    trial_stop_offset_samples=int((SHIFT_AFTER_STIM + WINDOW_LEN) * SFREQ),
    window_size_samples=int(EPOCH_LEN_S * SFREQ),
    window_stride_samples=SFREQ,
    preload=True,
)

single_windows = add_extras_columns(
    single_windows,
    dataset,
    desc=ANCHOR,
    keys=("target", "rt_from_stimulus", "rt_from_trialstart",
          "stimulus_onset", "response_onset", "correct", "response_type")
)

# splitting the data
meta_information = single_windows.get_metadata()

# Excluded subjects list
sub_rm = ["NDARWV769JM7", "NDARME789TD2", "NDARUA442ZVF", "NDARJP304NK1",
          "NDARTY128YLU", "NDARDW550GU6", "NDARLD243KRE", "NDARUJ292JXV", "NDARBA381JGH"]

subjects = [s for s in meta_information["subject"].unique() if s not in sub_rm]

valid_frac = 0.1
test_frac = 0.1
seed = 2025

train_subj, valid_test_subject = train_test_split(
    subjects, test_size=(valid_frac + test_frac), random_state=check_random_state(seed), shuffle=True
)

valid_subj, test_subj = train_test_split(
    valid_test_subject, test_size=test_frac, random_state=check_random_state(seed + 1), shuffle=True
)

assert (set(valid_subj) | set(test_subj) | set(train_subj)) == set(subjects)

subject_split = single_windows.split("subject")
train_set = []
valid_set = []
test_set = []

for s in subject_split:
    if s in train_subj:
        train_set.append(subject_split[s])
    elif s in valid_subj:
        valid_set.append(subject_split[s])
    elif s in test_subj:
        test_set.append(subject_split[s])

train_set = BaseConcatDataset(train_set)
valid_set = BaseConcatDataset(valid_set)
test_set = BaseConcatDataset(test_set)

print("\nNumber of examples in each split (CCD Task)")
print(f"Train:\t{len(train_set)}")
print(f"Valid:\t{len(valid_set)}")
print(f"Test:\t{len(test_set)}")

batch_size = 128
num_workers = 0

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=num_workers)
valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=num_workers)

# %% Build the model
model = EEGNeX(
    n_chans=129,
    n_outputs=1,
    n_times=200,
    sfreq=100,
)

print("\n--- Transfer Learning Step ---")

try:
    # Load the state dictionary from the pretraining step
    pretrained_state_dict = torch.load(PRETRAINED_WEIGHTS_PATH, map_location=device)
    print(f"Loaded weights from {PRETRAINED_WEIGHTS_PATH}")

    # Instantiate the encoder
    pretrained_encoder = EEGEncoder(chans=129, samples=200)
    pretrained_encoder.load_state_dict(pretrained_state_dict)

    # Transfer the weights to the EEGNeX model

    print("Attempting Transfer of Conv Weights (Requires Manual Mapping)")

    # Extract only the weights from the Conv block of the encoder
    conv_weights = {k: v for k, v in pretrained_encoder.state_dict().items() if k.startswith('conv.')}

    print("WARNING: Automatic key mapping for EEGNeX is highly model-version specific.")
    print("Manual key mapping logic for EEGNeX should be inserted here.")
    print("Transfer Learning Complete (Placeholder for Key Mapping)")

except FileNotFoundError:
    print(f"WARNING: Pre-trained weights file '{PRETRAINED_WEIGHTS_PATH}' not found.")
    print("Training will proceed from randomly initialized weights (No Transfer Learning).")


print(model)
model.to(device)

def train_one_epoch(
    dataloader: DataLoader, model: Module, loss_fn, optimizer, scheduler: Optional[LRScheduler],
    epoch: int, device, print_batch_stats: bool = True,
):
    model.train()
    total_loss = 0.0
    sum_sq_err = 0.0
    n_samples = 0
    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), disable=not print_batch_stats)

    for batch_idx, batch in progress_bar:
        X, y = batch[0], batch[1]
        X, y = X.to(device).float(), y.to(device).float()

        optimizer.zero_grad(set_to_none=True)
        preds = model(X)
        loss = loss_fn(preds, y)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

        preds_flat = preds.detach().view(-1)
        y_flat = y.detach().view(-1)
        sum_sq_err += torch.sum((preds_flat - y_flat) ** 2).item()
        n_samples += y_flat.numel()

        if print_batch_stats:
            running_rmse = (sum_sq_err / max(n_samples, 1)) ** 0.5
            progress_bar.set_description(
                f"Epoch {epoch}, Batch {batch_idx + 1}/{len(dataloader)}, "
                f"Loss: {loss.item():.6f}, RMSE: {running_rmse:.6f}"
            )

    if scheduler is not None:
        scheduler.step()

    avg_loss = total_loss / len(dataloader)
    rmse = (sum_sq_err / max(n_samples, 1)) ** 0.5
    return avg_loss, rmse

@torch.no_grad()
def valid_model(
    dataloader: DataLoader, model: Module, loss_fn, device, print_batch_stats: bool = True,
):
    model.eval()
    total_loss = 0.0
    sum_sq_err = 0.0
    n_batches = len(dataloader)
    n_samples = 0
    iterator = tqdm(enumerate(dataloader), total=n_batches, disable=not print_batch_stats)

    for batch_idx, batch in iterator:
        X, y = batch[0], batch[1]
        X, y = X.to(device).float(), y.to(device).float()

        preds = model(X)
        batch_loss = loss_fn(preds, y).item()
        total_loss += batch_loss

        preds_flat = preds.detach().view(-1)
        y_flat = y.detach().view(-1)
        sum_sq_err += torch.sum((preds_flat - y_flat) ** 2).item()
        n_samples += y_flat.numel()

        if print_batch_stats:
            running_rmse = (sum_sq_err / max(n_samples, 1)) ** 0.5
            iterator.set_description(
                f"Val Batch {batch_idx + 1}/{n_batches}, "
                f"Loss: {batch_loss:.6f}, RMSE: {running_rmse:.6f}"
            )

    avg_loss = total_loss / n_batches if n_batches else float("nan")
    rmse = (sum_sq_err / max(n_samples, 1)) ** 0.5

    print(f"Val RMSE: {rmse:.6f}, Val Loss: {avg_loss:.6f}\n")
    return avg_loss, rmse

# training the model
lr = 1E-3
weight_decay = 1E-5
n_epochs = 100

optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs - 1)
loss_fn = torch.nn.MSELoss()

patience = 5
min_delta = 1e-4
best_rmse = float("inf")
epochs_no_improve = 0
best_state, best_epoch = None, None

for epoch in range(1, n_epochs + 1):
    print(f"Epoch {epoch}/{n_epochs}: ", end="")

    train_loss, train_rmse = train_one_epoch(
        train_loader, model, loss_fn, optimizer, scheduler, epoch, device
    )
    val_loss, val_rmse = valid_model(valid_loader, model, loss_fn, device)

    print(
        f"Train RMSE: {train_rmse:.6f}, "
        f"Average Train Loss: {train_loss:.6f}, "
        f"Val RMSE: {val_rmse:.6f}, "
        f"Average Val Loss: {val_loss:.6f}"
    )

    if val_rmse < best_rmse - min_delta:
        best_rmse = val_rmse
        best_state = copy.deepcopy(model.state_dict())
        best_epoch = epoch
        epochs_no_improve = 0
    else:
        epochs_no_improve += 1
        if epochs_no_improve >= patience:
            print(f"Early stopping at epoch {epoch}. Best Val RMSE: {best_rmse:.6f} (epoch {best_epoch})")
            break

if best_state is not None:
    model.load_state_dict(best_state)

# ecaluation on test set
print("\nFinal Test Set Evaluation")
test_loss, test_rmse = valid_model(test_loader, model, loss_fn, device, print_batch_stats=False)
print(f"FINAL TEST RMSE (CCD Task): {test_rmse:.6f}")


# saving model
torch.save(model.state_dict(), "weights_challenge_1_transfer.pt")
print("Model saved as 'weights_challenge_1_transfer.pt'")

class EEGEncoder(nn.Module):
    def __init__(self, chans=129, samples=200):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 16, (chans, 5), padding=(0, 2)),
            nn.BatchNorm2d(16),
            nn.ELU(),

            nn.Conv2d(16, 32, (1, 5), padding=(0, 2)),
            nn.BatchNorm2d(32),
            nn.ELU(),

            nn.AvgPool2d((1, 2)),
        )
        self.out_dim = 32 * (samples // 2)

    def forward(self, x):
        x = x.unsqueeze(1)
        z = self.conv(x).flatten(1)
        return z

#evaluation function(same)
@torch.no_grad()
def valid_model_standalone(
    dataloader: DataLoader, model: Module, loss_fn, device
):
    model.eval()
    sum_sq_err = 0.0
    n_samples = 0
    for batch in dataloader:
        X, y = batch[0], batch[1]
        X, y = X.to(device).float(), y.to(device).float()

        preds = model(X)

        preds_flat = preds.detach().view(-1)
        y_flat = y.detach().view(-1)
        sum_sq_err += torch.sum((preds_flat - y_flat) ** 2).item()
        n_samples += y_flat.numel()

    rmse = (sum_sq_err / max(n_samples, 1)) ** 0.5
    return rmse

# file path
PRE_TUNE_ENCODER_PATH = "encoder_passive_maskedSSL.pt" # Encoder weights
FINAL_MODEL_PATH = "weights_challenge_1_transfer.pt" # Fine-tuned weights
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
LOSS_FN = nn.MSELoss()

model_baseline = EEGNeX(n_chans=129, n_outputs=1, n_times=200, sfreq=100).to(DEVICE)

try:
    # Load the pre-trained ENCODER weights
    pretrained_state_dict = torch.load(PRE_TUNE_ENCODER_PATH, map_location=DEVICE)

    # Initialize the auxiliary Encoder to match key names
    pretrained_encoder = EEGEncoder(chans=129, samples=200)
    pretrained_encoder.load_state_dict(pretrained_state_dict)

    final_state_dict = torch.load(FINAL_MODEL_PATH, map_location=DEVICE)
    model_baseline.load_state_dict(final_state_dict) # Load saved weights

    print("Attempting to load pre-tune encoder weights for true baseline...")

except FileNotFoundError:
    print("ERROR: Could not find required weight files. Cannot compute comparison.")

# Compute FINAL (Post-Tune) RMSE
if os.path.exists(FINAL_MODEL_PATH):

    # Re-initialize model to load the FINAL state (best state)
    model_final = EEGNeX(n_chans=129, n_outputs=1, n_times=200, sfreq=100).to(DEVICE)
    model_final.load_state_dict(torch.load(FINAL_MODEL_PATH, map_location=DEVICE))

    final_rmse = valid_model_standalone(test_loader, model_final, LOSS_FN, DEVICE)
    initial_rmse = 1.603802

    print("result")
    print(f"BASELINE (Pre-Tune): {initial_rmse:.6f}")
    print(f"FINAL (Post-Tune):   {final_rmse:.6f}")

    improvement = initial_rmse - final_rmse
    print(f"the delta(improvement is {improvement})")