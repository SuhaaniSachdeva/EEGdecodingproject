{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13956707,"sourceType":"datasetVersion","datasetId":8892113}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Dependencies: \n\nfrom pathlib import Path\nimport os\nimport math\nimport random\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils import clip_grad_norm_\n\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import pearsonr\n\nimport mne\nmne.set_log_level('ERROR')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:45:32.231872Z","iopub.execute_input":"2025-12-03T16:45:32.232450Z","iopub.status.idle":"2025-12-03T16:45:32.237639Z","shell.execute_reply.started":"2025-12-03T16:45:32.232428Z","shell.execute_reply":"2025-12-03T16:45:32.236631Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Configuration\nSFREQ = 100           # target sampling frequency (Hz)\nWIN_SEC = 4           # window length in seconds for pointers\nCROP_SEC = 2          # crop length (seconds) used for training window\nSTRIDE_SEC = 2        # stride in seconds for sliding windows\nTASK = \"contrastChangeDetection\"\n\n#defining paths of data\nDATA_ROOT = Path(\"/kaggle/input/eeg-mini\")\nTRAIN_RELEASES = [\"R10_mini_L100_bdf\"]#, \"R9_mini_L100_bdf\", \"R8_mini_L100_bdf\"]\nVAL_RELEASE = \"R11_mini_L100_bdf\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:45:38.993929Z","iopub.execute_input":"2025-12-03T16:45:38.994293Z","iopub.status.idle":"2025-12-03T16:45:38.998576Z","shell.execute_reply.started":"2025-12-03T16:45:38.994274Z","shell.execute_reply":"2025-12-03T16:45:38.997945Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Checkpoints code\nclass CheckpointSaver:\n    def __init__(self, save_path=\"/kaggle/working/best_model.pt\"):\n        self.best_val_loss = float(\"inf\")\n        self.save_path = save_path\n\n    def save_if_best(self, model, optimizer, epoch, val_loss):\n        \"\"\"Save full checkpoint when validation improves.\"\"\"\n        if val_loss < self.best_val_loss:\n            self.best_val_loss = val_loss\n            checkpoint = {\n                \"epoch\": epoch,\n                \"model_state\": model.state_dict(),\n                \"optimizer_state\": optimizer.state_dict(),\n                \"best_val_loss\": val_loss,\n            }\n            torch.save(checkpoint, self.save_path)\n            print(f\"✓ Saved BEST checkpoint at epoch {epoch+1} (val_loss={val_loss:.6f})\")\n\n    def save_periodic(self, model, optimizer, epoch):\n        \"\"\"Optional periodic checkpoint every N epochs.\"\"\"\n        path = f\"/kaggle/working/checkpoint_epoch_{epoch+1}.pt\"\n        checkpoint = {\n            \"epoch\": epoch,\n            \"model_state\": model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }\n        torch.save(checkpoint, path)\n        print(f\"✓ Periodic checkpoint saved: {path}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:45:44.499811Z","iopub.execute_input":"2025-12-03T16:45:44.500064Z","iopub.status.idle":"2025-12-03T16:45:44.505923Z","shell.execute_reply.started":"2025-12-03T16:45:44.500047Z","shell.execute_reply":"2025-12-03T16:45:44.505074Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Subjects to remove if corrupted\nSUB_RM = [] \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef seed_all(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_all(42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:45:48.583253Z","iopub.execute_input":"2025-12-03T16:45:48.583525Z","iopub.status.idle":"2025-12-03T16:45:48.683365Z","shell.execute_reply.started":"2025-12-03T16:45:48.583504Z","shell.execute_reply":"2025-12-03T16:45:48.682517Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Data loading functions\n\n#custom function to address issue with accessing nested releases, ie: /.../R6_L100_bdf/R6_L100_bdf/...\ndef resolve_double_nested_path(data_root: Path, release: str): \n    outer = data_root / release\n    inner = outer / release\n    if inner.exists() and (inner / \"participants.tsv\").exists():\n        return inner\n    elif outer.exists() and (outer / \"participants.tsv\").exists():\n        return outer\n    else:\n        return outer if outer.exists() else None\n\ndef load_participants_data(release_path: Path):\n    participants_file = release_path / \"participants.tsv\"\n    if not participants_file.exists():\n        return pd.DataFrame()\n    df = pd.read_csv(participants_file, sep='\\t')\n    return df\n\n#data loading function provided by competition\ndef load_raw_eeg(subject_path: Path, subject_id: str, task: str, run=None):\n    try:\n        if run is None:\n            fname = f\"sub-{subject_id}_task-{task}_eeg.bdf\"\n        else:\n            fname = f\"sub-{subject_id}_task-{task}_run-{run}_eeg.bdf\"\n\n        file_path = subject_path / \"eeg\" / fname\n\n        if not file_path.exists():\n            return None\n\n        raw = mne.io.read_raw_bdf(file_path, preload=False, verbose=False)\n        raw.load_data()\n\n        # Reject incomplete data\n        if raw.n_times < 4 * SFREQ or len(raw.ch_names) < 128:\n            return None\n\n        # Resample if needed\n        if int(raw.info['sfreq']) != SFREQ:\n            raw.resample(SFREQ)\n\n        return raw\n\n    except Exception as e:\n        print(\"EEG load failed:\", e)\n        return None\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:45:57.623165Z","iopub.execute_input":"2025-12-03T16:45:57.623782Z","iopub.status.idle":"2025-12-03T16:45:57.631031Z","shell.execute_reply.started":"2025-12-03T16:45:57.623758Z","shell.execute_reply":"2025-12-03T16:45:57.630332Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Lazy load functions.\n\"\"\"\"\"\nPurpose is to load large datasets into kaggle while addressing RAM crashing by \ninitializing and storing pointers to data instead of the entire dataset\n\"\"\"\"\"\n\ndef load_release_data_lazy(release, task=TASK, data_root=DATA_ROOT):\n    release_path = resolve_double_nested_path(data_root, release)\n    if release_path is None or not Path(release_path).exists():\n        print(f\"Warning: Release path not found for {release} under {data_root}\")\n        return []\n\n    release_path = Path(release_path)\n    participants_df = load_participants_data(release_path)\n    if participants_df.empty:\n        print(f\"No participants.tsv for {release}\")\n        return []\n\n    win_samples = int(WIN_SEC * SFREQ)\n    stride_samples = int(STRIDE_SEC * SFREQ)\n    bids_root = str(release_path)\n\n    window_pointers = []\n    for _, row in tqdm(participants_df.iterrows(), total=len(participants_df), desc=f\"Scanning {release}\"):\n        subj_col = row.get('participant_id', None)\n        if subj_col is None:\n            continue\n        subject_id = str(subj_col).replace('sub-', '')\n\n        if subject_id in SUB_RM:\n            continue\n\n        age = row.get('age', np.nan)\n        sex = row.get('sex', np.nan)\n        handedness = row.get('handedness', np.nan)\n        externalizing = row.get('externalizing', np.nan)\n        try:\n            externalizing = float(externalizing)\n            if not math.isfinite(externalizing):\n                continue\n        except Exception:\n            continue\n\n        sex_str = str(sex).strip().lower()\n        if sex_str in ['female', 'f', '2']:\n            sex_encoded = 1.0\n        elif sex_str in ['male', 'm', '1']:\n            sex_encoded = 0.0\n        else:\n            sex_encoded = np.nan\n\n        subject_path = release_path / f\"sub-{subject_id}\"\n        runs = [1, 2, 3] if task == \"contrastChangeDetection\" else [None]\n\n        for run in runs:\n            try:\n                if run is None:\n                    eeg_path = release_path / f\"sub-{subject_id}/eeg/sub-{subject_id}_task-{task}_eeg.bdf\"\n                else:\n                    eeg_path = release_path / f\"sub-{subject_id}/eeg/sub-{subject_id}_task-{task}_run-{run}_eeg.bdf\"\n                \n                if not eeg_path.exists():\n                    continue\n\n                raw = load_raw_eeg(subject_path, subject_id, task, run)\n                if raw is None:\n                    continue\n                n_times = raw.n_times\n                del raw\n\n                starts = range(0, n_times - win_samples + 1, stride_samples)\n                for start in starts:\n                    window_pointers.append({\n                        \"bids_root\": bids_root,\n                        \"subject\": subject_id,\n                        \"task\": task,\n                        \"run\": run,\n                        \"start_sample\": int(start),\n                        \"end_sample\": int(start + win_samples),\n                        \"age\": age,\n                        \"sex\": sex_encoded,\n                        \"handedness\": handedness,\n                        \"externalizing\": externalizing\n                    })\n            except Exception:\n                continue\n\n    print(f\"Scanned {len(window_pointers)} windows from {release}\")\n    return window_pointers\n\nclass EEGWindowsDataset(torch.utils.data.Dataset):\n    def __init__(self, data_list, crop_samples, keep_idx, seed=42, cache_size=3):\n        \"\"\"\n        data_list: list of pointers generated by load_release_data_lazy\n        crop_samples: number of time samples to crop (CROP_SEC * SFREQ)\n        keep_idx: demographic indices to keep. Add placeholder data since demographic data irreleveant \n        \"\"\"\n        self.data_list = data_list\n        self.crop_samples = int(crop_samples)\n        self.keep_idx = np.array(keep_idx, dtype=int) if (hasattr(keep_idx, '__len__') and len(keep_idx) > 0) else np.array([], dtype=int)\n        self.rng = random.Random(seed)\n        self.raw_cache = {}\n        self.cache_keys = []\n        self.cache_size = int(cache_size)\n\n        self._subject_paths = {}\n        for item in data_list:\n            key = (item['subject'], item['run'])\n            if key not in self._subject_paths:\n                bids_root = Path(item['bids_root'])\n                self._subject_paths[key] = bids_root / f\"sub-{item['subject']}\"\n\n    def __len__(self):\n        return len(self.data_list)\n\n    def _get_raw_from_cache(self, subject_id, run):\n        key = (subject_id, run)\n      \n        if key in self.raw_cache:\n            self.cache_keys.remove(key)\n            self.cache_keys.append(key)\n            return self.raw_cache[key]\n        item = next((it for it in self.data_list if (it['subject'], it['run']) == key), None)\n        if item is None:\n            raise FileNotFoundError(f\"No pointer found for {key}\")\n        subject_path = self._subject_paths[key]\n        raw = load_raw_eeg(subject_path, subject_id, item['task'], run)\n        if raw is None:\n            raise FileNotFoundError(f\"Could not load raw for {subject_id} run {run}\")\n        # insert into cache \n        if len(self.raw_cache) >= self.cache_size:\n            lru = self.cache_keys.pop(0)\n            del self.raw_cache[lru]\n        self.raw_cache[key] = raw\n        self.cache_keys.append(key)\n        return raw\n\n    def __getitem__(self, idx):\n        item = self.data_list[idx]\n        raw = self._get_raw_from_cache(item['subject'], item['run'])\n        # extract requested window\n        eeg_np, _ = raw[:, item['start_sample']:item['end_sample']]\n        # take first 128 channels if 129 present\n        if eeg_np.shape[0] >= 129:\n            eeg_np = eeg_np[:128, :]\n        eeg = torch.from_numpy(eeg_np.copy()).float()  # (channels, time)\n        C, T = eeg.shape\n        # pad or random crop to required crop_samples\n        if T < self.crop_samples:\n            pad_amount = int(self.crop_samples - T)\n            eeg = torch.nn.functional.pad(eeg, (0, pad_amount), mode='constant', value=0.0)\n            start_crop = 0\n            stop_crop = self.crop_samples\n        else:\n            start_crop = int(self.rng.randint(0, T - self.crop_samples))\n            stop_crop = int(start_crop + self.crop_samples)\n            eeg = eeg[:, start_crop:stop_crop]\n        # per-window z-score normalization across time (per channel)\n        mu = eeg.mean(dim=1, keepdim=True)\n        sd = eeg.std(dim=1, keepdim=True)\n        eeg = (eeg - mu) / (sd + 1e-6)\n        eeg = torch.nan_to_num(eeg, nan=0.0, posinf=0.0, neginf=0.0)\n        eeg = torch.clamp(eeg, min=-1e3, max=1e3)\n\n        # label\n        y = torch.tensor([item['externalizing']], dtype=torch.float32)\n\n        # demographics kept as placeholder \n        age = item['age']\n        try:\n            age = float(age) if (age is not None and math.isfinite(float(age))) else np.nan\n        except:\n            age = np.nan\n        sex = item['sex']\n        hand = item['handedness']\n        try:\n            hand = float(hand) if (hand is not None and math.isfinite(float(hand))) else np.nan\n        except:\n            hand = np.nan\n        full_demo = np.array([age, sex, hand], dtype=np.float32)\n        if self.keep_idx.size > 0:\n            demo = torch.from_numpy(full_demo[self.keep_idx]).float()\n        else:\n            demo = torch.empty(0, dtype=torch.float32)\n\n        info = {'subject': item['subject'], 'task': item['task'], 'run': item['run']}\n        crop_idx = (int(item['start_sample'] + start_crop), int(item['start_sample'] + stop_crop))\n\n        return eeg, y, demo, crop_idx, info\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:46:04.065787Z","iopub.execute_input":"2025-12-03T16:46:04.066056Z","iopub.status.idle":"2025-12-03T16:46:04.086812Z","shell.execute_reply.started":"2025-12-03T16:46:04.066036Z","shell.execute_reply":"2025-12-03T16:46:04.086052Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Scaler and demographics helper (kept for compatibility but fusion disabled)\n\nclass SafeStandardScaler(StandardScaler):\n    def fit(self, X, y=None):\n        super().fit(X, y)\n        if hasattr(self, \"scale_\"):\n            bad = ~np.isfinite(self.scale_) | (self.scale_ == 0)\n            self.scale_[bad] = 1.0\n        if hasattr(self, \"var_\"):\n            self.var_[~np.isfinite(self.var_)] = 0.0\n        if hasattr(self, \"mean_\"):\n            self.mean_[~np.isfinite(self.mean_)] = 0.0\n        return self\n\ndef extract_unique_demographics(data_list):\n    seen = {}\n    for item in data_list:\n        sid = item['subject']\n        if sid in seen:\n            continue\n        age = item['age']\n        try:\n            age = float(age) if (age is not None and math.isfinite(float(age))) else np.nan\n        except:\n            age = np.nan\n        sex = item['sex']\n        hand = item['handedness']\n        try:\n            hand = float(hand) if (hand is not None and math.isfinite(float(hand))) else np.nan\n        except:\n            hand = np.nan\n        seen[sid] = [age, sex, hand]\n    arr = np.array(list(seen.values()), dtype=np.float32) if seen else np.zeros((0, 3), dtype=np.float32)\n    return arr\n\n\ndef build_demo_transform(train_data):\n    \"\"\"\n    Keep the API: returns (demodim, transform_fn, medians, keep_idx)\n    But since we are disabling fusion will yield demodim=0.\n    \"\"\"\n    unique = extract_unique_demographics(train_data)\n    if unique.shape[0] == 0:\n        return 0, None, np.zeros((0,), dtype=np.float32), np.array([], dtype=int)\n    all_nan = np.isnan(unique).all(axis=0)\n    keep_mask = ~all_nan\n    keep_idx = np.where(keep_mask)[0]\n    kept = unique[:, keep_idx] if keep_idx.size > 0 else np.zeros((unique.shape[0], 0), dtype=np.float32)\n    if kept.shape[1] == 0:\n        return 0, None, np.zeros((0,), dtype=np.float32), np.array([], dtype=int)\n    with np.errstate(all='ignore'):\n        col_medians = np.nanmedian(kept, axis=0).astype(np.float32)\n        col_medians[~np.isfinite(col_medians)] = 0.0\n    def impute_cols(arr, meds):\n        out = arr.copy()\n        for j in range(out.shape[1]):\n            mask = ~np.isfinite(out[:, j])\n            out[mask, j] = meds[j]\n        return out\n    kept_imp = impute_cols(kept, col_medians)\n    scaler = SafeStandardScaler().fit(kept_imp)\n    def transform_batch(demo_tensor):\n        if demo_tensor.numel() == 0 or keep_idx.size == 0:\n            return demo_tensor.to(device=device, dtype=torch.float32)\n        demo_np = demo_tensor.detach().cpu().numpy().astype(np.float32)\n        for j in range(demo_np.shape[1]):\n            mask = ~np.isfinite(demo_np[:, j])\n            demo_np[mask, j] = col_medians[j]\n        demo_np = scaler.transform(demo_np)\n        out = torch.from_numpy(demo_np).to(device=device, dtype=torch.float32)\n        out = torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n        return out\n    return keep_idx.size, transform_batch, col_medians, keep_idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:47:33.833603Z","iopub.execute_input":"2025-12-03T16:47:33.834258Z","iopub.status.idle":"2025-12-03T16:47:33.846822Z","shell.execute_reply.started":"2025-12-03T16:47:33.834233Z","shell.execute_reply":"2025-12-03T16:47:33.846006Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Build data pointers and DataLoaders for loading into RAM\nprint(\"\\n\" + \"=\"*60)\nprint(\"Scanning mini-release and building pointers (lazy)...\")\nprint(\"=\"*60)\n\ntrain_data_pointers = []\nfor release in TRAIN_RELEASES:\n    train_data_pointers.extend(load_release_data_lazy(release, task=TASK, data_root=DATA_ROOT))\n\nprint(f\"\\nTotal training window pointers: {len(train_data_pointers)}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Loading validation pointers...\")\nprint(\"=\"*60)\nval_data_pointers = load_release_data_lazy(VAL_RELEASE, task=TASK, data_root=DATA_ROOT)\nprint(f\"Total validation window pointers: {len(val_data_pointers)}\")\n\n# Build (placeholder) demographic transform\ndemodim, transform_demo_batch, demo_medians, keep_idx = build_demo_transform(train_data_pointers)\n\n# Create datasets\nif len(train_data_pointers) == 0:\n    raise ValueError(\"No training windows found — check your mini release BIDS structure and TASK.\")\n\ntrain_dataset = EEGWindowsDataset(train_data_pointers, crop_samples=int(CROP_SEC * SFREQ), keep_idx=keep_idx, seed=42, cache_size=5)\nval_dataset   = EEGWindowsDataset(val_data_pointers, crop_samples=int(CROP_SEC * SFREQ), keep_idx=keep_idx, seed=42, cache_size=5)\n\nBATCH_SIZE = 32\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\nval_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n\n# Inferred shapes\nC, T = 128, int(CROP_SEC * SFREQ)\nprint(f\"\\nSample EEG shape: ({C}, {T})\")\nprint(f\"Demographic dims (kept): {demodim}\")\nprint(\"\\nDATA LOADING COMPLETE\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:47:50.645101Z","iopub.execute_input":"2025-12-03T16:47:50.645498Z","iopub.status.idle":"2025-12-03T16:48:11.666575Z","shell.execute_reply.started":"2025-12-03T16:47:50.645477Z","shell.execute_reply":"2025-12-03T16:48:11.665928Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nScanning mini-release and building pointers (lazy)...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Scanning R10_mini_L100_bdf: 100%|██████████| 20/20 [00:11<00:00,  1.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Scanned 9988 windows from R10_mini_L100_bdf\n\nTotal training window pointers: 9988\n\n============================================================\nLoading validation pointers...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Scanning R11_mini_L100_bdf: 100%|██████████| 20/20 [00:09<00:00,  2.07it/s]","output_type":"stream"},{"name":"stdout","text":"Scanned 8294 windows from R11_mini_L100_bdf\nTotal validation window pointers: 8294\n\nSample EEG shape: (128, 200)\nDemographic dims (kept): 2\n\nDATA LOADING COMPLETE\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Model \nclass EnhancedEEGNetRegressor(nn.Module):\n    def __init__(self, n_channels=128, n_times=200, dropout=0.25, F1=16, D=2):\n        super().__init__()\n        self.n_channels = n_channels\n        self.dropout_rate = dropout\n\n        # temporal conv\n        self.temporal_conv = nn.Conv2d(1, F1, kernel_size=(1, 51), stride=(1,1), padding=(0,25), bias=False)\n        self.bn1 = nn.BatchNorm2d(F1)\n\n        # spatial depthwise conv\n        self.spatial_conv = nn.Conv2d(F1, F1 * D, kernel_size=(n_channels, 1), stride=(1,1), groups=F1, bias=False)\n        self.bn2 = nn.BatchNorm2d(F1 * D)\n\n        self.elu = nn.ELU()\n        self.pool1 = nn.AvgPool2d(kernel_size=(1,4), stride=(1,4))\n        self.dropout1 = nn.Dropout(p=dropout)\n\n   \n        self.pool2 = nn.AvgPool2d(kernel_size=(1,2), stride=(1,2))\n        self.dropout2 = nn.Dropout(p=dropout)\n\n        self.eeg_feature_dim = F1 * D * (n_times // 8)  \n\n        # fusion / regression head \n        self.fusion = nn.Sequential(\n            nn.Linear(self.eeg_feature_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(p=dropout),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Dropout(p=dropout)\n        )\n        self.regression_head = nn.Linear(32, 1)\n\n    def forward(self, eeg, demographics=None):\n        # eeg expected shape: (B, 1, C, T)\n        x = self.temporal_conv(eeg)\n        x = self.bn1(x)\n        x = self.elu(x)\n\n        x = self.spatial_conv(x)\n        x = self.bn2(x)\n        x = self.elu(x)\n\n        x = self.pool1(x)\n        x = self.dropout1(x)\n\n \n        batch_size = x.size(0)\n        x = x.squeeze(2).unsqueeze(2)  # (B, F*, 1, time)\n        x = self.pool2(x)\n        x = self.dropout2(x)\n\n        eeg_features = x.reshape(batch_size, -1)\n        fused = self.fusion(eeg_features)\n        out = self.regression_head(fused)\n        return out\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:05:52.734250Z","iopub.execute_input":"2025-12-02T23:05:52.734818Z","iopub.status.idle":"2025-12-02T23:05:52.743316Z","shell.execute_reply.started":"2025-12-02T23:05:52.734791Z","shell.execute_reply":"2025-12-02T23:05:52.742507Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Loss, metrics, early stopping\n\nclass RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n    def forward(self, pred, target):\n        return torch.sqrt(self.mse(pred, target) + 1e-8)\n\nclass NRMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n    def forward(self, pred, target):\n        rmse = torch.sqrt(self.mse(pred, target) + 1e-8)\n        target_range = target.max() - target.min() + 1e-8\n        return rmse / target_range\n\ndef calculate_metrics(predictions, targets):\n    mse = np.mean((predictions - targets) ** 2)\n    rmse = np.sqrt(mse)\n    target_range = targets.max() - targets.min()\n    nrmse = rmse / (target_range + 1e-8)\n    mae = np.mean(np.abs(predictions - targets))\n    if len(predictions) > 1 and np.std(predictions) > 0 and np.std(targets) > 0:\n        corr, _ = pearsonr(predictions, targets)\n    else:\n        corr = 0.0\n    return {'mse': mse, 'rmse': rmse, 'nrmse': nrmse, 'mae': mae, 'pearson_r': corr}\n\nclass EarlyStoppingCallback:\n    def __init__(self, patience:int = 10, verbose: bool=True):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n    def __call__(self, val_loss: float, model: nn.Module, save_path: str = \"best_model.pt\"):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            torch.save(model.state_dict(), save_path)\n        elif val_loss < self.best_loss * 0.99:\n            self.best_loss = val_loss\n            self.counter = 0\n            torch.save(model.state_dict(), save_path)\n            if self.verbose:\n                print(f\"✓ Validation loss improved to {val_loss:.6f}. Model saved.\")\n        else:\n            self.counter += 1\n            if self.verbose:\n                print(f\"No improvement for {self.counter}/{self.patience} epochs\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n                if self.verbose:\n                    print(\"Early stopping triggered!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:05:58.098640Z","iopub.execute_input":"2025-12-02T23:05:58.098929Z","iopub.status.idle":"2025-12-02T23:05:58.108796Z","shell.execute_reply.started":"2025-12-02T23:05:58.098909Z","shell.execute_reply":"2025-12-02T23:05:58.108174Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Train / Validate functions\n\ndef train_epoch(model, train_loader, criterion, optimizer, device, grad_clip=1.0, transform_demo_batch=None):\n    model.train()\n    total_loss = 0.0\n    for eeg_batch, target_batch, demo_batch, _, _ in tqdm(train_loader, desc=\"Train\", leave=False):\n        eeg_batch = eeg_batch.unsqueeze(1).to(device)   # (B, 1, C, T)\n        target_batch = target_batch.to(device)\n        optimizer.zero_grad()\n        preds = model(eeg_batch)\n        loss = criterion(preds, target_batch)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(train_loader)\n\ndef validate_epoch(model, val_loader, criterion, device, transform_demo_batch=None):\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_targets = []\n    with torch.no_grad():\n        for eeg_batch, target_batch, demo_batch, _, _ in tqdm(val_loader, desc=\"Val\", leave=False):\n            eeg_batch = eeg_batch.unsqueeze(1).to(device)\n            target_batch = target_batch.to(device)\n            preds = model(eeg_batch)\n            loss = criterion(preds, target_batch)\n            total_loss += loss.item()\n            all_preds.append(preds.cpu().numpy())\n            all_targets.append(target_batch.cpu().numpy())\n    avg_loss = total_loss / len(val_loader)\n    preds = np.concatenate(all_preds, axis=0).flatten()\n    targets = np.concatenate(all_targets, axis=0).flatten()\n    return avg_loss, preds, targets\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:06:02.724905Z","iopub.execute_input":"2025-12-02T23:06:02.725416Z","iopub.status.idle":"2025-12-02T23:06:02.732931Z","shell.execute_reply.started":"2025-12-02T23:06:02.725392Z","shell.execute_reply":"2025-12-02T23:06:02.732154Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Model init, optimizer, scheduler\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"INITIALIZING MODEL\")\nprint(\"=\"*60)\n\nmodel = EnhancedEEGNetRegressor(n_channels=C, n_times=T, dropout=0.25, F1=16, D=2).to(device)\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"✓ Model created | total params: {total_params:,} | trainable: {trainable_params:,}\")\n\nN_EPOCHS = 10\nLEARNING_RATE = 1e-3\nEARLY_STOPPING_PATIENCE = 5\nUSE_NRMSE = False   \n\ncriterion = NRMSELoss() if USE_NRMSE else RMSELoss()\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\nearly_stopping = EarlyStoppingCallback(patience=EARLY_STOPPING_PATIENCE, verbose=True)\n\nhistory = {'train_loss': [], 'val_loss': [], 'val_rmse': [], 'val_mae': [], 'val_pearson_r': []}\nbest_model_path = \"/kaggle/working/best_eegnet_mini.pt\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T23:06:10.972448Z","iopub.execute_input":"2025-12-02T23:06:10.972721Z","iopub.status.idle":"2025-12-02T23:06:13.609751Z","shell.execute_reply.started":"2025-12-02T23:06:10.972701Z","shell.execute_reply":"2025-12-02T23:06:13.609019Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nINITIALIZING MODEL\n============================================================\n✓ Model created | total params: 58,385 | trainable: 58,385\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Training Loop with checkpoints\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING (with checkpoints)\")\nprint(\"=\"*60)\n\n# Initialize the checkpoint saver\ncheckpoint_saver = CheckpointSaver(\"/kaggle/working/best_model.pt\")\n\nfor epoch in range(N_EPOCHS):\n\n    print(f\"\\n{'='*60}\\nEpoch {epoch+1}/{N_EPOCHS}\\n{'='*60}\")\n\n    # TRAIN\n\n    train_loss = train_epoch(\n        model=model,\n        train_loader=train_loader,\n        criterion=criterion,\n        optimizer=optimizer,\n        device=device,\n        grad_clip=1.0\n        num_workers=0,\n    )\n\n    # VALIDATE\n\n    val_loss, val_preds, val_targets = validate_epoch(\n        model=model,\n        val_loader=val_loader,\n        criterion=criterion,\n        device=device\n        num_workers=0,\n    )\n\n    # METRICS & LOGGING\n\n    history['train_loss'].append(train_loss)\n    history['val_loss'].append(val_loss)\n\n    metrics = calculate_metrics(val_preds, val_targets)\n\n    history['val_rmse'].append(metrics['rmse'])\n    history['val_mae'].append(metrics['mae'])\n    history['val_pearson_r'].append(metrics['pearson_r'])\n\n    print(f\"Train Loss: {train_loss:.6f}\")\n    print(f\"Val Loss:   {val_loss:.6f} | RMSE: {metrics['rmse']:.6f} | \"\n          f\"MAE: {metrics['mae']:.6f} | r: {metrics['pearson_r']:.4f}\")\n\n    # LR SCHEDULING\n\n    scheduler.step(val_loss)\n\n    # CHECKPOINT SAVING\n\n    # Save best checkpoint\n    checkpoint_saver.save_if_best(\n        model=model,\n        optimizer=optimizer,\n        epoch=epoch,\n        val_loss=val_loss\n    )\n\n    # Save periodic checkpoints\n    if epoch % 5 == 0:\n        checkpoint_saver.save_periodic(model, optimizer, epoch)\n\n\n    # EARLY STOPPING\n\n    early_stopping(val_loss, model, best_model_path)\n\n    if early_stopping.early_stop:\n        print(f\"Early stopping triggered at epoch {epoch+1}\")\n        break\n\n\n# LOAD BEST CHECKPOINT AFTER TRAINING\ntry:\n    checkpoint = torch.load(\"/kaggle/working/best_model.pt\", map_location=device)\n    model.load_state_dict(checkpoint[\"model_state\"])\n    print(\"✓ Loaded BEST model checkpoint.\")\nexcept:\n    print(\"⚠ Could not load best checkpoint!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final evaluation + plotting\n\nval_loss, val_preds, val_targets = validate_epoch(\n    model,\n    val_loader,\n    criterion,\n    device,\n    transform_demo_batch=transform_demo_batch\n)\n\nfinal_metrics = calculate_metrics(val_preds, val_targets)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETE\")\nprint(\"=\"*60)\nprint(f\"Final Val RMSE:   {final_metrics['rmse']:.6f}\")\nprint(f\"Final Val nRMSE:  {final_metrics['nrmse']:.6f}\")\nprint(f\"Final Val MAE:    {final_metrics['mae']:.6f}\")\nprint(f\"Final Val Pearson r: {final_metrics['pearson_r']:.4f}\")\n\n# Plot training curves \n\nfig, axes = plt.subplots(2, 2, figsize=(12, 9))\n\n# Loss curves\naxes[0,0].plot(history['train_loss'], label='Train Loss')\naxes[0,0].plot(history['val_loss'], label='Val Loss')\naxes[0,0].legend()\naxes[0,0].set_title('Loss')\n\n# RMSE curve\naxes[0,1].plot(history['val_rmse'], label='Val RMSE')\naxes[0,1].set_title('Val RMSE')\naxes[0,1].legend()\n\n# MAE curve\naxes[1,0].plot(history['val_mae'], label='Val MAE')\naxes[1,0].set_title('Val MAE')\naxes[1,0].legend()\n\n# Pearson correlation\naxes[1,1].plot(history['val_pearson_r'], label='Val Pearson r')\naxes[1,1].set_title('Val Pearson r')\naxes[1,1].legend()\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/training_history.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"Saved training curves to /kaggle/working/training_history.png\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T18:13:11.068728Z","iopub.status.idle":"2025-12-02T18:13:11.069075Z","shell.execute_reply.started":"2025-12-02T18:13:11.068959Z","shell.execute_reply":"2025-12-02T18:13:11.068971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}