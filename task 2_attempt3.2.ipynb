{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13944918,"sourceType":"datasetVersion","datasetId":8885317}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mne==1.10.1 mne-bids==0.17.0 --quiet\n!pip install scikit-learn --quiet\nfrom pathlib import Path\nimport os, math, random\nfrom collections import defaultdict\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils import clip_grad_norm_\n\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.stats import pearsonr\n\nimport mne\nfrom mne_bids import BIDSPath, read_raw_bids\nmne.set_log_level('ERROR')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:11:00.089838Z","iopub.execute_input":"2025-12-01T21:11:00.090578Z","iopub.status.idle":"2025-12-01T21:11:16.747388Z","shell.execute_reply.started":"2025-12-01T21:11:00.090542Z","shell.execute_reply":"2025-12-01T21:11:16.746622Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"SFREQ = 100  # Sampling rate (Hz)\nWIN_SEC = 4  # Window size (seconds)\nCROP_SEC = 2  # Random crop size (seconds)\nSTRIDE_SEC = 2  # Window stride (seconds)\nTASK = \"contrastChangeDetection\"  # Primary task\n\n# Path to the parent folder containing R6_L100_bdf and R5_L100_bdf\nDATA_ROOT = Path(\"/kaggle/input/eeg-dataset\")\n\nTRAIN_RELEASES = [\"R6_L100_bdf\",\"R7_L100_bdf\",\"R8_L100_bdf\"]\nVAL_RELEASE = \"R5_L100_bdf\"\n\nSUB_RM = [\"NDARAC350XUM\", \"NDARAJ689BVN\"] \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef seed_all(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_all(42)\n\n\ndef resolve_double_nested_path(data_root, release):\n    outer = data_root / release\n    inner = outer / release\n    if (inner.exists() and (inner / \"participants.tsv\").exists()):\n        return inner\n    elif (outer.exists() and (outer / \"participants.tsv\").exists()):\n        return outer\n    else:\n        return None\n\ndef load_participants_data(release_path):\n    participants_file = release_path / \"participants.tsv\"\n    if not participants_file.exists():\n        return pd.DataFrame()\n    df = pd.read_csv(participants_file, sep='\\t')\n    return df\n\n# Helper to load RAW data for a subject/run (Used by the cache and the dataset)\ndef load_raw_eeg(subject_path, subject_id, task, run=None):\n    \"\"\"Load a single EEG file using MNE-BIDS. Returns mne.io.Raw object.\"\"\"\n    try:\n        # BIDS_ROOT is subject_path.parent\n        bids_path = BIDSPath(\n            subject=subject_id,\n            task=task,\n            run=run,\n            datatype='eeg',\n            extension='.bdf',\n            root=subject_path.parent\n        )\n        raw = read_raw_bids(bids_path, verbose=False)\n        raw.load_data()\n        \n        # Validation checks\n        if raw.n_times < 4 * SFREQ or len(raw.ch_names) != 129:\n             return None\n             \n        return raw\n    except Exception:\n        return None\n\ndef load_release_data_lazy(release, task=TASK, data_root=DATA_ROOT):\n    \"\"\"\n    Scans the data and returns a list of *window pointers* (metadata), \n    not the actual EEG data, to avoid filling RAM.\n    \"\"\"\n    release_path = resolve_double_nested_path(data_root, release)\n\n    if not release_path.exists():\n        print(f\"Warning: Release path {release_path} not found\")\n        return []\n\n    participants_df = load_participants_data(release_path)\n\n    if participants_df.empty:\n        print(f\"No participants data found for {release}\")\n        return []\n\n    window_pointers = []\n    win_samples = int(WIN_SEC * SFREQ)\n    stride_samples = int(STRIDE_SEC * SFREQ)\n    \n    # Store the BIDS root for easier access later\n    bids_root = str(release_path)\n\n    for _, row in tqdm(\n        participants_df.iterrows(),\n        total=len(participants_df),\n        desc=f\"Scanning {release} for windows\"\n    ):\n        subject_id = row['participant_id'].replace('sub-', '')\n\n        if subject_id in SUB_RM:\n            continue\n\n        # Extract demographics and label\n        age = row.get('age', np.nan)\n        sex = row.get('sex', np.nan)\n        handedness = row.get('handedness', np.nan)\n        externalizing = row.get('externalizing', np.nan)\n        \n        try:\n            externalizing = float(externalizing)\n            if not math.isfinite(externalizing):\n                continue\n        except Exception:\n            continue\n            \n        sex_str = str(sex).strip().lower()\n        if sex_str in ['female', 'f', '2']:\n            sex_encoded = 1.0\n        elif sex_str in ['male', 'm', '1']:\\\n            sex_encoded = 0.0\n        else:\n            sex_encoded = np.nan\n        \n        # Path to subject directory inside the resolved release folder\n        subject_path = release_path / f\"sub-{subject_id}\"\n\n        runs = [1, 2, 3] if task == \"contrastChangeDetection\" else [None]\n\n        for run in runs:\n            try:\n                # Pre-check if the file exists and its length\n                # NOTE: This is less robust than calling load_raw_eeg, but much faster \n                # for generating pointers. We'll rely on load_raw_eeg failing later.\n                bids_path_check = BIDSPath(\n                    subject=subject_id, task=task, run=run, datatype='eeg', extension='.bdf', root=release_path\n                )\n                if not bids_path_check.fpath.exists():\n                    continue\n\n                # We MUST load data here to know the total length for windowing, \n                # but we'll minimize its lifetime.\n                raw = load_raw_eeg(subject_path, subject_id, task, run)\n                if raw is None:\n                    continue\n\n                n_times = raw.n_times\n                del raw # IMMEDIATELY RELEASE MEMORY\n\n                starts = range(0, n_times - win_samples + 1, stride_samples)\n                \n                # Store pointers\n                for start in starts:\n                    window_pointers.append({\n                        \"bids_root\": bids_root,\n                        \"subject\": subject_id,\n                        \"task\": task,\n                        \"run\": run,\n                        \"start_sample\": start,\n                        \"end_sample\": start + win_samples,\n                        \"age\": age,\n                        \"sex\": sex_encoded,\n                        \"handedness\": handedness,\n                        \"externalizing\": externalizing,\n                    })\n\n            except Exception:\n                continue\n\n    print(f\"Scanned and generated {len(window_pointers)} window pointers from {release}\")\n    return window_pointers\n\n\nclass EEGWindowsDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Dataset that lazily loads EEG data from disk using MNE-BIDS path metadata,\n    and uses a simple LRU cache to keep the last few raw files in memory.\n    \"\"\"\n    def __init__(self, data_list, crop_samples, keep_idx, seed=42, cache_size=3):\n        self.data_list = data_list\n        self.crop_samples = crop_samples\n        self.keep_idx = keep_idx\n        self.rng = random.Random(seed)\n        \n        # Simple cache for raw objects to speed up repeated access to the same file\n        self.raw_cache = {} \n        self.cache_keys = []\n        self.cache_size = cache_size\n        \n        # For memory efficiency, pre-calculate path to subject folder\n        self._subject_paths = {}\n        for item in data_list:\n            key = (item['subject'], item['run'])\n            if key not in self._subject_paths:\n                bids_root = Path(item['bids_root'])\n                self._subject_paths[key] = bids_root / f\"sub-{item['subject']}\"\n    \n    def __len__(self):\n        return len(self.data_list)\n\n    def _get_raw_from_cache(self, subject_id, run):\n        \"\"\"Fetches raw object from cache or loads it from disk.\"\"\"\n        key = (subject_id, run)\n        \n        # 1. Hit: Move key to front (MRU)\n        if key in self.raw_cache:\n            self.cache_keys.remove(key)\n            self.cache_keys.append(key)\n            return self.raw_cache[key]\n        \n        # 2. Miss: Load from disk\n        item = next(item for item in self.data_list if (item['subject'], item['run']) == key)\n        subject_path = self._subject_paths[key]\n\n        raw = load_raw_eeg(subject_path, subject_id, item['task'], run)\n        \n        if raw is None:\n            raise FileNotFoundError(f\"Could not load raw file for {subject_id}, run {run}\")\n            \n        # 3. Add to cache (LRU eviction)\n        if len(self.raw_cache) >= self.cache_size:\n            lru_key = self.cache_keys.pop(0) # Pop oldest (LRU)\n            del self.raw_cache[lru_key]\n        \n        self.raw_cache[key] = raw\n        self.cache_keys.append(key)\n        \n        return raw\n\n    def __getitem__(self, idx):\n        item = self.data_list[idx]\n        \n        # LAZY LOAD: Get the raw MNE object (either from cache or disk)\n        raw = self._get_raw_from_cache(item['subject'], item['run'])\n        \n        # Extract the window using MNE method for safe memory access\n        eeg, _ = raw[:, item['start_sample']:item['end_sample']]\n        # MNE returns (n_channels, n_times)\n        \n        # Take first 128 channels if 129 present\n        if eeg.shape[0] == 129:\n            eeg = eeg[:128, :]\n        \n        # Convert to tensor and apply crop/normalization (rest of your original logic)\n        eeg = torch.from_numpy(eeg.copy()).float()\n        C, T = eeg.shape\n        \n        # Random crop\n        if T < self.crop_samples:\n            pad_amount = self.crop_samples - T\n            eeg = torch.nn.functional.pad(eeg, (0, pad_amount), mode='constant', value=0)\n            start_crop = 0\n            stop_crop = self.crop_samples\n        else:\n            start_crop = self.rng.randint(0, T - self.crop_samples)\n            stop_crop = start_crop + self.crop_samples\n            eeg = eeg[:, start_crop:stop_crop]\n        \n        # Per-window z-score normalization\n        mu = eeg.mean(dim=1, keepdim=True)\n        sd = eeg.std(dim=1, keepdim=True)\n        eeg = (eeg - mu) / (sd + 1e-6)\n        eeg = torch.nan_to_num(eeg, nan=0.0, posinf=0.0, neginf=0.0)\n        eeg = torch.clamp(eeg, min=-1e3, max=1e3)\n        \n        # Get label and demographics (mostly copied from your original code)\n        y = torch.tensor([item['externalizing']], dtype=torch.float32)\n        \n        age = item['age']\n        try:\n            age = float(age) if age is not None and math.isfinite(float(age)) else np.nan\n        except:\n            age = np.nan\n        \n        sex = item['sex']\n        hand = item['handedness']\n        try:\n            hand = float(hand) if hand is not None and math.isfinite(float(hand)) else np.nan\n        except:\n            hand = np.nan\n        \n        full_demo = np.array([age, sex, hand], dtype=np.float32)\n        if len(self.keep_idx) > 0:\n            demo = torch.from_numpy(full_demo[self.keep_idx])\n        else:\n            demo = torch.empty(0, dtype=torch.float32)\n        \n        info = {\n            'subject': item['subject'],\n            'task': item['task'],\n            'run': item['run'],\n        }\n        crop_idx = (item['start_sample'] + start_crop, item['start_sample'] + stop_crop)\n        \n        return eeg, y, demo, crop_idx, info\n\n\ndef extract_unique_demographics(data_list):\n    seen = {}\n    for item in data_list:\n        sid = item['subject']\n        if sid in seen:\n            continue\n        \n        age = item['age']\n        try:\n            age = float(age) if age is not None and math.isfinite(float(age)) else np.nan\n        except:\n            age = np.nan\n        \n        sex = item['sex']\n        hand = item['handedness']\n        try:\n            hand = float(hand) if hand is not None and math.isfinite(float(hand)) else np.nan\n        except:\n            hand = np.nan\n        \n        seen[sid] = [age, sex, hand]\n    \n    arr = np.array(list(seen.values()), dtype=np.float32) if seen else np.zeros((0, 3), dtype=np.float32)\n    return arr\n\nclass SafeStandardScaler(StandardScaler):\n    def fit(self, X, y=None):\n        super().fit(X, y)\n        if hasattr(self, \"scale_\"):\n            bad = ~np.isfinite(self.scale_) | (self.scale_ == 0)\n            self.scale_[bad] = 1.0\n        if hasattr(self, \"var_\"):\n            self.var_[~np.isfinite(self.var_)] = 0.0\n        if hasattr(self, \"mean_\"):\n            self.mean_[~np.isfinite(self.mean_)] = 0.0\n        return self\n\ndef build_demo_transform(train_data):\n    unique = extract_unique_demographics(train_data)\n    \n    if unique.shape[0] == 0:\n        print(\"No demographics found; disabling late fusion.\")\n        return 0, None, np.zeros((0,), dtype=np.float32), np.array([], dtype=int)\n    \n    all_nan = np.isnan(unique).all(axis=0)\n    keep_mask = ~all_nan\n    keep_idx = np.where(keep_mask)[0]\n    keep_names = [n for n, k in zip(['age', 'sex', 'hand'], keep_mask) if k]\n    print(\"Keeping demo columns:\", keep_names)\n    \n    kept = unique[:, keep_idx] if keep_idx.size > 0 else np.zeros((unique.shape[0], 0), dtype=np.float32)\n    \n    if kept.shape[1] == 0:\n        print(\"No usable demographic columns; disabling late fusion.\")\n        return 0, None, np.zeros((0,), dtype=np.float32), np.array([], dtype=int)\n    \n    with np.errstate(all='ignore'):\n        col_medians = np.nanmedian(kept, axis=0).astype(np.float32)\n        col_medians[~np.isfinite(col_medians)] = 0.0\n    \n    def impute_cols(arr, meds):\n        out = arr.copy()\n        for j in range(out.shape[1]):\n            mask = ~np.isfinite(out[:, j])\n            out[mask, j] = meds[j]\n        return out\n    \n    kept_imp = impute_cols(kept, col_medians)\n    scaler = SafeStandardScaler().fit(kept_imp)\n    print(f\"Demo scaler fitted on {kept_imp.shape[0]} subjects | dims: {keep_idx.size}\")\n    \n    def transform_batch(demo_tensor):\n        if demo_tensor.numel() == 0 or keep_idx.size == 0:\n            return demo_tensor.to(device=device, dtype=torch.float32)\n        \n        demo_np = demo_tensor.detach().cpu().numpy().astype(np.float32)\n        for j in range(demo_np.shape[1]):\n            mask = ~np.isfinite(demo_np[:, j])\n            demo_np[mask, j] = col_medians[j]\n        \n        demo_np = scaler.transform(demo_np)\n        out = torch.from_numpy(demo_np).to(device=device, dtype=torch.float32)\n        out = torch.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)\n        return out\n    \n    return keep_idx.size, transform_batch, col_medians, keep_idx\n\n\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Loading training releases...\")\nprint(\"=\"*60)\n\n# *** NOW CALLING load_release_data_lazy ***\ntrain_data_pointers = []\nfor release in TRAIN_RELEASES:\n    train_data_pointers.extend(load_release_data_lazy(release, task=TASK, data_root=DATA_ROOT)) \n\nprint(f\"\\n✓ Total training windows (pointers): {len(train_data_pointers)}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"Loading validation release...\")\nprint(\"=\"*60)\n\nval_data_pointers = load_release_data_lazy(VAL_RELEASE, TASK, DATA_ROOT)\nprint(f\"✓ Total validation windows (pointers): {len(val_data_pointers)}\")\n\n# Build demographics\nprint(\"\\n\" + \"=\"*60)\nprint(\"Building demographic transformations...\")\nprint(\"=\"*60)\ndemodim, transform_demo_batch, demo_medians, keep_idx = build_demo_transform(train_data_pointers)\n\n# Create datasets\nprint(\"\\n\" + \"=\"*60)\nprint(\"Creating PyTorch datasets...\")\nprint(\"=\"*60)\n\nif len(train_data_pointers) == 0:\n    raise ValueError(\"No training window pointers found – check your BIDS structure and data validity!\")\n\ntrain_dataset = EEGWindowsDataset(\n    train_data_pointers,\n    crop_samples=int(CROP_SEC * SFREQ),\n    keep_idx=keep_idx,\n    seed=42,\n    cache_size=5 # Cache the 5 most recently accessed raw files\n)\n\nval_dataset = EEGWindowsDataset(\n    val_data_pointers,\n    crop_samples=int(CROP_SEC * SFREQ),\n    keep_idx=keep_idx,\n    seed=42,\n    cache_size=5 \n)\n\n# DataLoaders\nBATCH_SIZE = 32\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=4, \n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n\n# T=200 for 2-second crop\nC, T = 128, int(CROP_SEC * SFREQ) \nprint(f\"\\n✓ Train batches: {len(train_loader)}\")\nprint(f\"✓ Val batches: {len(val_loader)}\")\nprint(f\"\\n✓ Sample EEG shape: ({C}, {T})\")\nprint(f\"✓ Demographic features: {demodim}\")\nprint(\"\\n\" + \"=\"*60)\nprint(\"DATA LOADING COMPLETE!\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T21:12:01.331070Z","iopub.execute_input":"2025-12-01T21:12:01.331511Z","iopub.status.idle":"2025-12-01T21:24:55.342971Z","shell.execute_reply.started":"2025-12-01T21:12:01.331486Z","shell.execute_reply":"2025-12-01T21:24:55.342162Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nLoading training releases...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Scanning R6_L100_bdf for windows: 100%|██████████| 135/135 [01:35<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Scanned and generated 32789 window pointers from R6_L100_bdf\n","output_type":"stream"},{"name":"stderr","text":"Scanning R7_L100_bdf for windows: 100%|██████████| 381/381 [03:37<00:00,  1.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Scanned and generated 81065 window pointers from R7_L100_bdf\n","output_type":"stream"},{"name":"stderr","text":"Scanning R8_L100_bdf for windows: 100%|██████████| 257/257 [03:45<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Scanned and generated 93674 window pointers from R8_L100_bdf\n\n✓ Total training windows (pointers): 207528\n\n============================================================\nLoading validation release...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Scanning R5_L100_bdf for windows: 100%|██████████| 330/330 [03:55<00:00,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"Scanned and generated 106562 window pointers from R5_L100_bdf\n✓ Total validation windows (pointers): 106562\n\n============================================================\nBuilding demographic transformations...\n============================================================\nKeeping demo columns: ['age', 'sex']\nDemo scaler fitted on 486 subjects | dims: 2\n\n============================================================\nCreating PyTorch datasets...\n============================================================\n\n✓ Train batches: 6486\n✓ Val batches: 3331\n\n✓ Sample EEG shape: (128, 200)\n✓ Demographic features: 2\n\n============================================================\nDATA LOADING COMPLETE!\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim: int, num_heads: int = 8, dropout: float = 0.3):\n        super().__init__()\n        self.attention = nn.MultiheadAttention(\n            embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True\n        )\n    def forward(self, x):\n        attn_output, _ = self.attention(x, x, x)\n        return attn_output\n\nclass EnhancedEEGNetRegressor(nn.Module):\n    def __init__(self, n_channels: int = 128, n_times: int = 200, n_demographic_features: int = 3, dropout: float = 0.5, F1: int = 16, D: int = 2, num_heads: int = 8):\n        super().__init__()\n        self.n_channels = n_channels\n        self.dropout_rate = dropout\n        self.temporal_conv = nn.Conv2d(1, F1, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25), bias=False)\n        self.bn1 = nn.BatchNorm2d(F1)\n        self.spatial_conv = nn.Conv2d(F1, F1 * D, kernel_size=(n_channels, 1), stride=(1, 1), groups=F1, bias=False)\n        self.bn2 = nn.BatchNorm2d(F1 * D)\n        self.elu = nn.ELU()\n        self.pool1 = nn.AvgPool2d(kernel_size=(1, 4), stride=(1, 4))\n        self.dropout1 = nn.Dropout(p=dropout)\n        self.attention = MultiHeadAttention(embed_dim=F1 * D, num_heads=num_heads, dropout=dropout)\n        self.pool2 = nn.AvgPool2d(kernel_size=(1, 2), stride=(1, 2))\n        self.dropout2 = nn.Dropout(p=dropout)\n        self.eeg_feature_dim = F1 * D * (n_times // 8) # 32 * 25 = 800 for 200 samples\n        \n        self.demographic_encoder = nn.Sequential(\n            nn.Linear(n_demographic_features, 16), nn.ReLU(), nn.Dropout(p=dropout), nn.Linear(16, 32)\n        )\n        fusion_input_dim = self.eeg_feature_dim + 32 if n_demographic_features > 0 else self.eeg_feature_dim\n        self.fusion = nn.Sequential(\n            nn.Linear(fusion_input_dim, 64), nn.ReLU(), nn.Dropout(p=dropout),\n            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(p=dropout)\n        )\n        self.regression_head = nn.Linear(32, 1)\n    \n    def forward(self, eeg: torch.Tensor, demographics: torch.Tensor = None):\n        x = self.temporal_conv(eeg)\n        x = self.bn1(x)\n        x = self.elu(x)\n        x = self.spatial_conv(x)\n        x = self.bn2(x)\n        x = self.elu(x)\n        x = self.pool1(x)\n        x = self.dropout1(x)\n        batch_size = x.shape[0]\n        x = x.squeeze(2).transpose(1, 2)\n        x = self.attention(x)\n        x = x.transpose(1, 2).unsqueeze(2)\n        x = self.pool2(x)\n        x = self.dropout2(x)\n        eeg_features = x.view(batch_size, -1)\n        \n        if demographics is not None and demographics.numel() > 0:\n            demo_features = self.demographic_encoder(demographics)\n            combined_features = torch.cat([eeg_features, demo_features], dim=1)\n        else:\n            combined_features = eeg_features\n        \n        fused = self.fusion(combined_features)\n        output = self.regression_head(fused)\n        return output\n\n# Loss and Metric functions\nclass RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n    def forward(self, pred, target):\n        return torch.sqrt(self.mse(pred, target) + 1e-8)\n\nclass NRMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n    def forward(self, pred, target):\n        rmse = torch.sqrt(self.mse(pred, target) + 1e-8)\n        target_range = target.max() - target.min() + 1e-8\n        return rmse / target_range\n\ndef calculate_metrics(predictions, targets):\n    mse = np.mean((predictions - targets) ** 2)\n    rmse = np.sqrt(mse)\n    target_range = targets.max() - targets.min()\n    nrmse = rmse / (target_range + 1e-8)\n    mae = np.mean(np.abs(predictions - targets))\n    if len(predictions) > 1 and np.std(predictions) > 0 and np.std(targets) > 0:\n        corr, _ = pearsonr(predictions, targets)\n    else:\n        corr = 0.0\n    return {'mse': mse, 'rmse': rmse, 'nrmse': nrmse, 'mae': mae, 'pearson_r': corr}\n\n\nclass EarlyStoppingCallback:\n    def __init__(self, patience: int = 3, verbose: bool = True):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n    \n    def __call__(self, val_loss: float, model: nn.Module, save_path: str = \"best_model.pt\"):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n            torch.save(model.state_dict(), save_path)\n        elif val_loss < self.best_loss * 0.99:\n            self.best_loss = val_loss\n            self.counter = 0\n            torch.save(model.state_dict(), save_path)\n            if self.verbose:\n                print(f\"✓ Validation loss improved to {val_loss:.6f}. Model saved.\")\n        else:\n            self.counter += 1\n            if self.verbose:\n                print(f\"No improvement for {self.counter}/{self.patience} epochs\")\n            if self.counter >= self.patience:\n                self.early_stop = True\n                if self.verbose:\n                    print(\"Early stopping triggered!\")\n\ndef train_epoch(model, train_loader, criterion, optimizer, device, transform_demo_batch=None):\n    model.train()\n    total_loss = 0.0\n\n    for eeg_batch, target_batch, demo_batch, _, _ in train_loader:\n        # (B, C, T) -> (B, 1, C, T) and move to GPU\n        eeg_batch = eeg_batch.unsqueeze(1).to(device, non_blocking=True)\n        target_batch = target_batch.to(device, non_blocking=True)\n\n        if demo_batch is not None and demo_batch.numel() > 0:\n            demo_batch = demo_batch.to(device, non_blocking=True)\n        else:\n            demo_batch = None\n\n        if transform_demo_batch is not None and demo_batch is not None and demo_batch.numel() > 0:\n            demo_batch = transform_demo_batch(demo_batch)\n\n        optimizer.zero_grad()\n        preds = model(eeg_batch, demo_batch)     # runs on GPU\n        loss = criterion(preds, target_batch)    # on GPU\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(train_loader)\n\ndef validate_epoch(model, val_loader, criterion, device, transform_demo_batch=None):\n    model.eval()\n    total_loss = 0.0\n    all_preds, all_targets = [], []\n\n    with torch.no_grad():\n        for eeg_batch, target_batch, demo_batch, _, _ in val_loader:\n            eeg_batch = eeg_batch.unsqueeze(1).to(device, non_blocking=True)\n            target_batch = target_batch.to(device, non_blocking=True)\n\n            if demo_batch is not None and demo_batch.numel() > 0:\n                demo_batch = demo_batch.to(device, non_blocking=True)\n            else:\n                demo_batch = None\n\n            if transform_demo_batch is not None and demo_batch is not None and demo_batch.numel() > 0:\n                demo_batch = transform_demo_batch(demo_batch)\n\n            preds = model(eeg_batch, demo_batch)\n            loss = criterion(preds, target_batch)\n\n            total_loss += loss.item()\n            all_preds.append(preds.detach().cpu().numpy())\n            all_targets.append(target_batch.detach().cpu().numpy())\n\n    avg_loss = total_loss / len(val_loader)\n    all_preds = np.concatenate(all_preds, axis=0).flatten()\n    all_targets = np.concatenate(all_targets, axis=0).flatten()\n    return avg_loss, all_preds, all_targets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T22:14:39.677080Z","iopub.execute_input":"2025-12-01T22:14:39.677915Z","iopub.status.idle":"2025-12-01T22:14:39.703507Z","shell.execute_reply.started":"2025-12-01T22:14:39.677882Z","shell.execute_reply":"2025-12-01T22:14:39.702750Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*60)\nprint(\"INITIALIZING MODEL\")\nprint(\"=\"*60)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\nmodel = EnhancedEEGNetRegressor(\n    n_channels=C,\n    n_times=T,\n    n_demographic_features=demodim,\n    dropout=0.25,\n    F1=16,\n    D=2,\n    num_heads=8,\n).to(device)\n\ncriterion = NRMSELoss().to(device)\n\nprint(\"Model device:\", next(model.parameters()).device)\n\n\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\"✓ Model created on {device}\")\nprint(f\"✓ Total parameters: {total_params:,}\")\nprint(f\"✓ Trainable parameters: {trainable_params:,}\")\nprint(\"=\"*60)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*60)\n\nN_EPOCHS = 100\nLEARNING_RATE = 0.001\nEARLY_STOPPING_PATIENCE = 15\nUSE_NRMSE = True\n\nif USE_NRMSE:\n    criterion = NRMSELoss().to(device)   # loss on GPU\n    print(\"Using nRMSE loss\")\nelse:\n    criterion = RMSELoss().to(device)    # loss on GPU\n    print(\"Using RMSE loss\")\n\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True\n)\n\nearly_stopping = EarlyStoppingCallback(patience=EARLY_STOPPING_PATIENCE, verbose=True)\n\nhistory = {\n    \"train_loss\": [],\n    \"val_loss\": [],\n    \"val_rmse\": [],\n    \"val_mae\": [],\n    \"val_pearson_r\": [],\n}\n\nbest_model_path = \"/kaggle/working/best_enhanced_eegnet.pt\"\n\nfor epoch in range(N_EPOCHS):\n    print(f\"\\n{'='*60}\")\n    print(f\"Epoch {epoch + 1}/{N_EPOCHS}\")\n    print(f\"{'='*60}\")\n\n    train_loss = train_epoch(\n        model,\n        train_loader,\n        criterion,\n        optimizer,\n        device,\n        transform_demo_batch=transform_demo_batch,\n    )\n    history[\"train_loss\"].append(train_loss)\n    print(f\"Train Loss: {train_loss:.6f}\")\n\n    # validate_epoch must also move its batches to device internally\n    val_loss, val_preds, val_targets = validate_epoch(\n        model,\n        val_loader,\n        criterion,\n        device,\n        transform_demo_batch=transform_demo_batch,\n    )\n    history[\"val_loss\"].append(val_loss)\n\n    metrics = calculate_metrics(val_preds, val_targets)\n    history[\"val_rmse\"].append(metrics[\"rmse\"])\n    history[\"val_mae\"].append(metrics[\"mae\"])\n    history[\"val_pearson_r\"].append(metrics[\"pearson_r\"])\n\n    print(f\"Val Loss: {val_loss:.6f}\")\n    print(f\"Val RMSE: {metrics['rmse']:.6f}\")\n    print(f\"Val nRMSE: {metrics['nrmse']:.6f}\")\n    print(f\"Val MAE: {metrics['mae']:.6f}\")\n    print(f\"Val Pearson r: {metrics['pearson_r']:.4f}\")\n\n    scheduler.step(val_loss)\n\n    early_stopping(val_loss, model, best_model_path)\n    if early_stopping.early_stop:\n        print(f\"\\n✓ Early stopping at epoch {epoch + 1}\")\n        break\n\ntry:\n    state_dict = torch.load(best_model_path, map_location=device)\n    model.load_state_dict(state_dict)\n    model.to(device)\n    print(f\"\\n✓ Loaded best model from {best_model_path} onto {device}\")\nexcept Exception as e:\n    print(f\"\\nWarning: Could not load best model state dict ({e}). Using model from last epoch.\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING COMPLETE!\")\nprint(\"=\"*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T22:19:23.862954Z","iopub.execute_input":"2025-12-01T22:19:23.863778Z","iopub.status.idle":"2025-12-01T22:19:36.332152Z","shell.execute_reply.started":"2025-12-01T22:19:23.863749Z","shell.execute_reply":"2025-12-01T22:19:36.330769Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nINITIALIZING MODEL\n============================================================\nDevice: cuda\nModel device: cuda:0\n✓ Model created on cuda\n✓ Total parameters: 65,249\n✓ Trainable parameters: 65,249\n============================================================\n\n============================================================\nSTARTING TRAINING\n============================================================\nUsing nRMSE loss\n\n============================================================\nEpoch 1/100\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x78f0d3b06840>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x78f0d3b06840>\nself._shutdown_workers()Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nif w.is_alive():Exception ignored in: \n    <function _MultiProcessingDataLoaderIter.__del__ at 0x78f0d3b06840> if w.is_alive(): \n\n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        self._shutdown_workers()   \n  ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n ^    ^^if w.is_alive():^^^\n^^ ^ ^^ ^ ^^  ^^ Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x78f0d3b06840>^\n^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\nTraceback (most recent call last):\n^^    \n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nassert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n        \n^assert self._parent_pid == os.getpid(), 'can only test a child process' self._shutdown_workers()^\n\n^  ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^      ^if w.is_alive():  \n\n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n          assert self._parent_pid == os.getpid(), 'can only test a child process'  \n             ^^ ^ ^ ^^^ ^^^ ^^ ^^^ ^^^ ^^^^^^ ^ ^^^^^^^^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^^^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^^^ ^ ^^^ ^^^  ^^^ ^ ^^^ ^^ ^^^^ ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^\n^^AssertionErrorAssertionError^^: : ^^^can only test a child processcan only test a child process^\n\n\n^AssertionError^: can only test a child process^\n^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2384987324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'='*60}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     train_loss = train_epoch(\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/3401981063.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer, device, transform_demo_batch)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0meeg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# (B, C, T) -> (B, 1, C, T) and move to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0meeg_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meeg_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\naxes[0, 0].plot(history['train_loss'], label='Train Loss', linewidth=2)\naxes[0, 0].plot(history['val_loss'], label='Val Loss', linewidth=2)\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('Loss')\naxes[0, 0].set_title('Training and Validation Loss')\naxes[0, 0].legend()\naxes[0, 0].grid(True)\n\naxes[0, 1].plot(history['val_rmse'], label='Val RMSE', linewidth=2, color='orange')\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('RMSE')\naxes[0, 1].set_title('Validation RMSE')\naxes[0, 1].legend()\naxes[0, 1].grid(True)\n\naxes[1, 0].plot(history['val_mae'], label='Val MAE', linewidth=2, color='green')\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('MAE')\naxes[1, 0].set_title('Validation MAE')\naxes[1, 0].legend()\naxes[1, 0].grid(True)\n\naxes[1, 1].plot(history['val_pearson_r'], label='Val Pearson r', linewidth=2, color='red')\naxes[1, 1].set_xlabel('Epoch')\naxes[1, 1].set_ylabel('Pearson r')\naxes[1, 1].set_title('Validation Pearson Correlation')\naxes[1, 1].legend()\naxes[1, 1].grid(True)\n\nplt.tight_layout()\nplt.savefig('/kaggle/working/training_history.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"✓ Training curves saved to training_history.png\")\n\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"FINAL EVALUATION\")\nprint(\"=\"*60)\n\nval_loss, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device, transform_demo_batch=transform_demo_batch)\nfinal_metrics = calculate_metrics(val_preds, val_targets)\n\nprint(f\"Final Val RMSE: {final_metrics['rmse']:.6f}\")\nprint(f\"Final Val MAE: {final_metrics['mae']:.6f}\")\nprint(f\"Final Val Pearson r: {final_metrics['pearson_r']:.4f}\")\nprint(\"=\"*60)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}